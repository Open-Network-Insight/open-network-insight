#spot.conf should always be located in /etc/spot.conf
#file formated as standard .INI

[DEFAULT]
#base user and data source config
#HDFS
HUSER=/user/spot
DSOURCES=flow dns proxy
DFOLDERS=binary csv hive stage
##removing FDATE for now*********
HPATH=%(HUSER)s/%(DSOURCE)s/scored_results/
#local fs
LUSER=/home/spot
LPATH=%(LUSER)s/ml/%(DSOURCE)s/%(FDATE)s
RPATH=%(LUSER)s/ipython/user/%(FDATE)s
LDAPATH=%(LUSER)s/ml/oni-lda-c
LIPATH=%(LUSER)s/ingest
#Spot architecture
#list where each Spot component will run from
UINODE=node03
MLNODE=node04
GWNODE=node16
MAXRESULTS=3000
TOL=1e-6
NODES=
    node-01
    node-02

[database]
IMPALA_DEM=node04
DBNAME=spot

[kerberos]
KRB_AUTH=false
KINITPATH=
KINITOPTS=
KEYTABPATH=
KRB_USER=


[spark]
SPK_CONFIG=False
SPK_EXEC=400
SPK_EXEC_MEM=2048m
SPK_DRIVER_MEM=None
SPK_DRIVER_MAX_RESULTS=None
SPK_EXEC_CORES=None
SPK_DRIVER_MEM_OVERHEAD=None
SPK_EXEC_MEM_OVERHEAD=None

[mpi]
#command to run MPI
MPI_CMD=mpiexec
#command to prepare system for MPI, eg. load environment variables
MPI_PREP_CMD=
#number of processes to run in MPI
PROCESS_COUNT=20

[ingest]
hdfs_app_path=hdfs application path
kafka_server=kafka ip
kafka_port=9183
zookeeper_server=localhost
zookeeper_port=2181
message_size=999999

[flow]
type=flow
collector_path=/path_to_flow_collector
local_staging=/tmp/
process_opt=""
FLOW_PATH=%(HUSER)s/%(DSOURCE)s/hive/y=%(YR)s/m=%(MH)s/d=%(DY)s/

[dns]
type=dns
collector_path=/path_to_dns_collector
local_staging=/tmp/
pcap_split_staging=/tmp/
process_opt="-E separator=, -E header=y -E occurrence=f -T fields -e frame.time -e frame.time_epoch -e frame.len -e ip.src -e ip.dst -e dns.resp.name -e dns.resp.type -e dns.resp.class -e dns.flags.rcode -e dns.a 'dns.flags.response == 1'"
DNS_PATH=%(HUSER)s/%(DSOURCE)s/hive/y=%(YR)s/m=%(MH)s/d=%(DY)s/

[proxy]
type=proxy
collector_path=/path_to_proxy_collector
supported_files=["log"]
parser=bro_parser.py
PROXY_PATH=%(HUSER)s/%(DSOURCE)s/hive/y=%(YR)s/m=%(MH)s/d=%(DY)s/
